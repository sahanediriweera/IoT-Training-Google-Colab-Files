{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"IoT Project Test 3.ipynb","provenance":[],"mount_file_id":"1CDQWd2ABQ17LHZpW5fybr5ba9a-6GuD7","authorship_tag":"ABX9TyMXYciteE/N+pUrNtnuHCK5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IpiDnEMrmWDz"},"outputs":[],"source":[""]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OTwpDthVw7DP","executionInfo":{"status":"ok","timestamp":1650034641842,"user_tz":-330,"elapsed":25392,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}},"outputId":"af647f90-7ba4-4aec-cbcd-a166db15e5a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/IoT Test project 2')"],"metadata":{"id":"Roql6DHMxojv","executionInfo":{"status":"ok","timestamp":1650083384344,"user_tz":-330,"elapsed":379,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import torch\n","from PIL import Image\n","\n","class PennFundanDataset(torch.utils.data.Dataset):\n","  def __init__(self,root,transforms):\n","      self.root= root\n","      self.transforms = transforms\n","\n","      self.imgs = list(sorted(os.listdir(\"/content/drive/MyDrive/Colab Notebooks/IoT Test project 2/PNGImages\")))\n","      self.masks = list(sorted(os.listdir(\"/content/drive/MyDrive/Colab Notebooks/IoT Test project 2/PedMasks\")))\n","\n","\n","  def __getitem__(self,idx):\n","    img_path = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/IoT Test project 2/PNGImages\",self.imgs[idx])\n","    mask_path = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/IoT Test project 2/PedMasks\",self.masks[idx])\n","\n","    img = Image.open(img_path).convert(\"RGB\")\n","\n","    mask = Image.open(mask_path)\n","\n","    mask = np.array(mask)\n","\n","    obj_ids = np.unique(mask)\n","\n","    obj_ids = obj_ids[1:]\n","\n","    masks = mask == obj_ids[:,None,None]\n","\n","    num_objs = len(obj_ids)\n","\n","    boxes = []\n","\n","    for i in range(num_objs):\n","      pos = np.where(masks[i])\n","      xmin = np.min(pos[1])\n","      xmax = np.max(pos[1])\n","      ymin = np.min(pos[0])\n","      ymax = np.max(pos[0])\n","\n","      boxes.append([xmin,ymin,xmax,ymax])\n","\n","    boxes = torch.as_tensor(boxes,dtype = torch.float32)\n","\n","    labels = torch.ones((num_objs,),dtype=torch.int64)\n","    masks = torch.as_tensor(masks,dtype=torch.uint8)\n","\n","    image_id = torch.tensor([idx])\n","    area = (boxes[:,3]-boxes[:,1])*(boxes[:,2]-boxes[:,0])\n","\n","    iscrowd = torch.zeros((num_objs,),dtype=torch.int64)\n","\n","    target = {}\n","\n","    target[\"boxes\"] = boxes\n","    target[\"labels\"] = labels\n","    target[\"masks\"] = masks\n","    target[\"image_id\"] = image_id\n","    target[\"area\"] = area\n","    target[\"iscrowd\"] = iscrowd\n","\n","    if self.transforms is not None:\n","      img, target = self.transforms(img, target)\n","\n","    return img,target\n","\n","  def __len__(self):\n","    return len(self.imgs)\n","\n","\n","\n","\n","\n"],"metadata":{"id":"dWceRGjLxyyO","executionInfo":{"status":"ok","timestamp":1650085686573,"user_tz":-330,"elapsed":1056,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["import torchvision\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","\n","num_classes =2 \n","\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)"],"metadata":{"id":"FBKZ_Hmatc5O","executionInfo":{"status":"ok","timestamp":1650083393343,"user_tz":-330,"elapsed":1008,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["import torchvision\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.rpn import AnchorGenerator\n","\n","backbone = torchvision.models.mobilenet_v2(pretrained=True).features\n","backbone.out_channels = 1280\n","\n","anchor_generator = AnchorGenerator(sizes=((32,64,128,256,512),),aspect_ratios=((0.5,1.0,2.0),))\n","\n","roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'],output_size=7,sampling_ratio=2)\n","\n","model = FasterRCNN(backbone,num_classes=2,rpn_anchor_generator=anchor_generator,box_roi_pool=roi_pooler)\n","\n"],"metadata":{"id":"Bgm-jSH2vhay","executionInfo":{"status":"ok","timestamp":1650083398125,"user_tz":-330,"elapsed":1470,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["import torchvision\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n","\n","def get_model_instance_segmentation(num_classes):\n","\n","  model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n","\n","  in_features = model.roi_heads.box_predictor.cls_score.in_features\n","\n","  model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)\n","\n","  in_feaures_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n","  hidden_layer = 256\n","\n","  model.roi_heads.mask_predictor = MaskRCNNPredictor(in_feaures_mask,hidden_layer,num_classes)\n","\n","  return model\n","\n","\n","\n"],"metadata":{"id":"HaF7nAo9x3fD","executionInfo":{"status":"ok","timestamp":1650083401200,"user_tz":-330,"elapsed":382,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/drive/MyDrive/Colab Notebooks/IoT Test project 2/visionmain/references/detection')\n","\n"],"metadata":{"id":"CjWdJVe44IjW","executionInfo":{"status":"ok","timestamp":1650083404620,"user_tz":-330,"elapsed":2,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["pip install torch-util"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LaHi1VcnG63","executionInfo":{"status":"ok","timestamp":1650083411289,"user_tz":-330,"elapsed":3346,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}},"outputId":"0a558818-73eb-4aef-aad4-edeb99babefa"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch-util in /usr/local/lib/python3.7/dist-packages (0.0.0.0a0.dev20210602)\n"]}]},{"cell_type":"code","source":["from torchvision import transforms as T\n","def get_transforms(train):\n","  transforms = []\n","  transforms.append(torchvision.transforms.ToTensor())\n","  if train:\n","    transforms.append(T.RandomHorizontalFlip(0.5))\n","  return torchvision.transforms.Compose(transforms)"],"metadata":{"id":"K2_YnRYjAasN","executionInfo":{"status":"ok","timestamp":1650083428605,"user_tz":-330,"elapsed":420,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import numpy as np\n","\n","def collate_fn(batch):\n","    data_list, label_list = [], []\n","    for _data, _label in batch:\n","        data_list.append(_data)\n","        label_list.append(_label)\n","    return torch.Tensor(data_list), torch.LongTensor(label_list)"],"metadata":{"id":"DsSAKiSelWUw","executionInfo":{"status":"ok","timestamp":1650083432036,"user_tz":-330,"elapsed":395,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","dataset = PennFundanDataset('PennFundanDataset',get_transforms(train=True))\n","data_loader = torch.utils.data.DataLoader(\n"," dataset, batch_size=2, shuffle=True, num_workers=4,\n"," collate_fn=collate_fn)\n","# For Training\n","images,targets = next(iter(data_loader))\n","images = list(image for image in images)\n","targets = [{k: v for k, v in t.items()} for t in targets]\n","output = model(images,targets)   # Returns losses and detections\n","# For inference\n","model.eval()\n","x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n","predictions = model(x)   "],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":660},"id":"SUWNIets4pWP","executionInfo":{"status":"error","timestamp":1650085715244,"user_tz":-330,"elapsed":21797,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}},"outputId":"2a39d139-d3ce-40aa-baf6-bc41556e8007"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-1541f934edfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m  collate_fn=collate_fn)\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# For Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 49, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-52-ddf4656316e0>\", line 64, in __getitem__\n    img, target = self.transforms(img, target)\nTypeError: __call__() takes 2 positional arguments but 3 were given\n"]}]}]}