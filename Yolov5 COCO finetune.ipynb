{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Yolov5 COCO finetune.ipynb","provenance":[],"authorship_tag":"ABX9TyOFYbiJkdl+Yazufhj4O9/S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rP2G-0eK33uW","executionInfo":{"status":"ok","timestamp":1652353310355,"user_tz":-330,"elapsed":3048,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}},"outputId":"2e64d2a3-a7bb-4096-b820-aa7a73f091af"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 13320, done.\u001b[K\n","remote: Counting objects: 100% (43/43), done.\u001b[K\n","remote: Compressing objects: 100% (14/14), done.\u001b[K\n","remote: Total 13320 (delta 30), reused 38 (delta 29), pack-reused 13277\u001b[K\n","Receiving objects: 100% (13320/13320), 12.00 MiB | 23.41 MiB/s, done.\n","Resolving deltas: 100% (9278/9278), done.\n"]}],"source":["!git clone https://github.com/ultralytics/yolov5 "]},{"cell_type":"code","source":["!wget http://images.cocodataset.org/zips/train2017.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_rlWH3qx_pOm","executionInfo":{"status":"ok","timestamp":1652354608294,"user_tz":-330,"elapsed":236204,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}},"outputId":"ef34f961-b6b9-4255-cb65-7c881856575f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-05-12 11:19:32--  http://images.cocodataset.org/zips/train2017.zip\n","Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.132.145\n","Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.132.145|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19336861798 (18G) [application/zip]\n","Saving to: â€˜train2017.zipâ€™\n","\n","train2017.zip       100%[===================>]  18.01G  81.5MB/s    in 3m 56s  \n","\n","2022-05-12 11:23:28 (78.2 MB/s) - â€˜train2017.zipâ€™ saved [19336861798/19336861798]\n","\n"]}]},{"cell_type":"code","source":["!cd yolov5 && python train.py --img 640 --batch 16 --epochs 10 --freeze 20 --data coco.yaml --weights yolov5s.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e-Tak6dcBXke","executionInfo":{"status":"ok","timestamp":1652357648175,"user_tz":-330,"elapsed":19844,"user":{"displayName":"Sahan Ediriweera","userId":"10749579122675065975"}},"outputId":"fc133b71-fba8-4ea3-fc09-19963c309d60"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=coco.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[20], save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n","YOLOv5 ðŸš€ v6.1-178-g4870064 torch 1.11.0+cu113 CPU\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=1\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","Model summary: 270 layers, 7022326 parameters, 7022326 gradients\n","\n","Transferred 343/349 items from yolov5s.pt\n","freezing model.0.conv.weight\n","freezing model.0.bn.weight\n","freezing model.0.bn.bias\n","freezing model.1.conv.weight\n","freezing model.1.bn.weight\n","freezing model.1.bn.bias\n","freezing model.2.cv1.conv.weight\n","freezing model.2.cv1.bn.weight\n","freezing model.2.cv1.bn.bias\n","freezing model.2.cv2.conv.weight\n","freezing model.2.cv2.bn.weight\n","freezing model.2.cv2.bn.bias\n","freezing model.2.cv3.conv.weight\n","freezing model.2.cv3.bn.weight\n","freezing model.2.cv3.bn.bias\n","freezing model.2.m.0.cv1.conv.weight\n","freezing model.2.m.0.cv1.bn.weight\n","freezing model.2.m.0.cv1.bn.bias\n","freezing model.2.m.0.cv2.conv.weight\n","freezing model.2.m.0.cv2.bn.weight\n","freezing model.2.m.0.cv2.bn.bias\n","freezing model.3.conv.weight\n","freezing model.3.bn.weight\n","freezing model.3.bn.bias\n","freezing model.4.cv1.conv.weight\n","freezing model.4.cv1.bn.weight\n","freezing model.4.cv1.bn.bias\n","freezing model.4.cv2.conv.weight\n","freezing model.4.cv2.bn.weight\n","freezing model.4.cv2.bn.bias\n","freezing model.4.cv3.conv.weight\n","freezing model.4.cv3.bn.weight\n","freezing model.4.cv3.bn.bias\n","freezing model.4.m.0.cv1.conv.weight\n","freezing model.4.m.0.cv1.bn.weight\n","freezing model.4.m.0.cv1.bn.bias\n","freezing model.4.m.0.cv2.conv.weight\n","freezing model.4.m.0.cv2.bn.weight\n","freezing model.4.m.0.cv2.bn.bias\n","freezing model.4.m.1.cv1.conv.weight\n","freezing model.4.m.1.cv1.bn.weight\n","freezing model.4.m.1.cv1.bn.bias\n","freezing model.4.m.1.cv2.conv.weight\n","freezing model.4.m.1.cv2.bn.weight\n","freezing model.4.m.1.cv2.bn.bias\n","freezing model.5.conv.weight\n","freezing model.5.bn.weight\n","freezing model.5.bn.bias\n","freezing model.6.cv1.conv.weight\n","freezing model.6.cv1.bn.weight\n","freezing model.6.cv1.bn.bias\n","freezing model.6.cv2.conv.weight\n","freezing model.6.cv2.bn.weight\n","freezing model.6.cv2.bn.bias\n","freezing model.6.cv3.conv.weight\n","freezing model.6.cv3.bn.weight\n","freezing model.6.cv3.bn.bias\n","freezing model.6.m.0.cv1.conv.weight\n","freezing model.6.m.0.cv1.bn.weight\n","freezing model.6.m.0.cv1.bn.bias\n","freezing model.6.m.0.cv2.conv.weight\n","freezing model.6.m.0.cv2.bn.weight\n","freezing model.6.m.0.cv2.bn.bias\n","freezing model.6.m.1.cv1.conv.weight\n","freezing model.6.m.1.cv1.bn.weight\n","freezing model.6.m.1.cv1.bn.bias\n","freezing model.6.m.1.cv2.conv.weight\n","freezing model.6.m.1.cv2.bn.weight\n","freezing model.6.m.1.cv2.bn.bias\n","freezing model.6.m.2.cv1.conv.weight\n","freezing model.6.m.2.cv1.bn.weight\n","freezing model.6.m.2.cv1.bn.bias\n","freezing model.6.m.2.cv2.conv.weight\n","freezing model.6.m.2.cv2.bn.weight\n","freezing model.6.m.2.cv2.bn.bias\n","freezing model.7.conv.weight\n","freezing model.7.bn.weight\n","freezing model.7.bn.bias\n","freezing model.8.cv1.conv.weight\n","freezing model.8.cv1.bn.weight\n","freezing model.8.cv1.bn.bias\n","freezing model.8.cv2.conv.weight\n","freezing model.8.cv2.bn.weight\n","freezing model.8.cv2.bn.bias\n","freezing model.8.cv3.conv.weight\n","freezing model.8.cv3.bn.weight\n","freezing model.8.cv3.bn.bias\n","freezing model.8.m.0.cv1.conv.weight\n","freezing model.8.m.0.cv1.bn.weight\n","freezing model.8.m.0.cv1.bn.bias\n","freezing model.8.m.0.cv2.conv.weight\n","freezing model.8.m.0.cv2.bn.weight\n","freezing model.8.m.0.cv2.bn.bias\n","freezing model.9.cv1.conv.weight\n","freezing model.9.cv1.bn.weight\n","freezing model.9.cv1.bn.bias\n","freezing model.9.cv2.conv.weight\n","freezing model.9.cv2.bn.weight\n","freezing model.9.cv2.bn.bias\n","freezing model.10.conv.weight\n","freezing model.10.bn.weight\n","freezing model.10.bn.bias\n","freezing model.13.cv1.conv.weight\n","freezing model.13.cv1.bn.weight\n","freezing model.13.cv1.bn.bias\n","freezing model.13.cv2.conv.weight\n","freezing model.13.cv2.bn.weight\n","freezing model.13.cv2.bn.bias\n","freezing model.13.cv3.conv.weight\n","freezing model.13.cv3.bn.weight\n","freezing model.13.cv3.bn.bias\n","freezing model.13.m.0.cv1.conv.weight\n","freezing model.13.m.0.cv1.bn.weight\n","freezing model.13.m.0.cv1.bn.bias\n","freezing model.13.m.0.cv2.conv.weight\n","freezing model.13.m.0.cv2.bn.weight\n","freezing model.13.m.0.cv2.bn.bias\n","freezing model.14.conv.weight\n","freezing model.14.bn.weight\n","freezing model.14.bn.bias\n","freezing model.17.cv1.conv.weight\n","freezing model.17.cv1.bn.weight\n","freezing model.17.cv1.bn.bias\n","freezing model.17.cv2.conv.weight\n","freezing model.17.cv2.bn.weight\n","freezing model.17.cv2.bn.bias\n","freezing model.17.cv3.conv.weight\n","freezing model.17.cv3.bn.weight\n","freezing model.17.cv3.bn.bias\n","freezing model.17.m.0.cv1.conv.weight\n","freezing model.17.m.0.cv1.bn.weight\n","freezing model.17.m.0.cv1.bn.bias\n","freezing model.17.m.0.cv2.conv.weight\n","freezing model.17.m.0.cv2.bn.weight\n","freezing model.17.m.0.cv2.bn.bias\n","freezing model.18.conv.weight\n","freezing model.18.bn.weight\n","freezing model.18.bn.bias\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/datasets/coco/train2017.cache' images and labels... 117266 found, 1021 missing, 0 empty, 0 corrupt: 100% 118287/118287 [00:00<?, ?it/s]\n","Traceback (most recent call last):\n","  File \"train.py\", line 667, in <module>\n","    main(opt)\n","  File \"train.py\", line 562, in main\n","    train(opt.hyp, opt, device, callbacks)\n","  File \"train.py\", line 238, in train\n","    assert mlc < nc, f'Label class {mlc} exceeds nc={nc} in {data}. Possible class labels are 0-{nc - 1}'\n","AssertionError: Label class 79 exceeds nc=1 in /content/yolov5/data/coco.yaml. Possible class labels are 0-0\n"]}]}]}